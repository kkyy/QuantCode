{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import backtrader as bt\n",
    "import matplotlib.pyplot as plt \n",
    "import tushare as ts\n",
    "import akshare as ak\n",
    "import sys,os\n",
    "\n",
    "\n",
    "sys.stdout.encoding = 'utf_8_sig'\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99239373",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = pd.read_csv('stock_list.csv', encoding='utf_8_sig')\n",
    "stock_list_CSI300 = ak.index_stock_cons_csindex(symbol=\"000300\") #å¯¼å…¥æ²ªæ·±300æˆåˆ†è‚¡çš„æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec79ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#è·Ÿstock_listä¸­çš„ä»£ç å¯¹æ¯”ï¼Œæ˜¾ç¤ºæ²¡æœ‰çš„æ•°æ®\n",
    "files = os.listdir('Data_k')\n",
    "files.sort()\n",
    "files[0][files[0].find('_')+1:files[0].find('_')+10]\n",
    "Codes = []\n",
    "for file in files:\n",
    "    Codes.append(file[file.find('_')+1:file.find('_')+10])\n",
    "stock_list = pd.read_csv('stock_list.csv', encoding='utf_8_sig')\n",
    "stocks_none = stock_list[~stock_list['Code'].isin(Codes)]\n",
    "#stocks_none = [x for x in stock_list['Code'] if x not in Codes]\n",
    "print(stocks_none)\n",
    "\n",
    "#ç”Ÿæˆåå¤æƒçš„æ”¶ç›˜ä»·\n",
    "# stock1 = pd.read_csv(\"Data_k/\"+files[300], encoding='utf_8_sig')\n",
    "# stock1.head()\n",
    "\n",
    "#å¯¼å‡ºè´¢åŠ¡æ•°æ®ï¼ŒPE PBç­‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80fcf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f41a78",
   "metadata": {},
   "source": [
    "# è®¡ç®—é™¤å¤æƒä»·æ ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a921a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_k = pd.DataFrame()\n",
    "for file in files[0:4]:\n",
    "    df = pd.read_csv('Data_k/'+file, encoding='utf_8_sig')\n",
    "    if len(df) == 0:\n",
    "        print(file, \"æ•°æ®ä¸ºç©º\")\n",
    "        continue\n",
    "    # è®¡ç®—æ¶¨è·Œå¹…\n",
    "    df['chg'] = df['close'].shift(1) / df['pre_close'] - 1\n",
    "    df.iloc[0,11] = 0 #ç¬¬11åˆ—ä¸º'chg'\n",
    "    # =è®¡ç®—å¤æƒä»·: è®¡ç®—æ‰€æœ‰å› å½“å½“ä¸­ç”¨åˆ°çš„ä»·æ ¼, éƒ½ä½¿ç”¨å¤æƒä»·\n",
    "    df['adj_factor'] = (1 + df['chg']).cumprod()\n",
    "\n",
    "    label = 'after'  # é€‰æ‹©å¤æƒæ¨¡å¼çš„æ ‡ç­¾\n",
    "    # è®¡ç®—åå¤æƒä»·æ ¼\n",
    "    if label == 'after':\n",
    "        df['adj_after_close'] = df['adj_factor'] * df['close']\n",
    "    # è®¡ç®—å‰å¤æƒä»·æ ¼\n",
    "    if label == 'pre':\n",
    "        df['adj_pre_close'] = df['adj_factor'] * (\n",
    "                df.iloc[-1]['close'] / df.iloc[-1]['adj_factor'])\n",
    "    stock_k = pd.concat([stock_k, df], axis=0)\n",
    "\n",
    "stock_k['trade_date'] = pd.to_datetime(stock_k['trade_date'].astype(\"str\"))\n",
    "stock_k.set_index(\"trade_date\",inplace=True,drop=True)\n",
    "# # è®¡ç®—å…¶ä»–ä»·æ ¼çš„å¤æƒ\n",
    "# df['å¼€ç›˜ä»·%så¤æƒ' % label] = df['å¼€ç›˜ä»·'] / df['æ”¶ç›˜ä»·'] * df['æ”¶ç›˜ä»·%så¤æƒ' % label]\n",
    "# df['æœ€é«˜ä»·%så¤æƒ' % label] = df['æœ€é«˜ä»·'] / df['æ”¶ç›˜ä»·'] * df['æ”¶ç›˜ä»·%så¤æƒ' % label]\n",
    "# df['æœ€ä½ä»·%så¤æƒ' % label] = df['æœ€ä½ä»·'] / df['æ”¶ç›˜ä»·'] * df['æ”¶ç›˜ä»·%så¤æƒ' % label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69fd3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_k(syboml):\n",
    "    df = stock_k[stock_k[\"ts_code\"]==syboml][[\"open\",\"high\",\"low\",\"adj_after_close\",\"vol\"]]\n",
    "    df['openinterest'] = 0\n",
    "    df.rename(columns={\"adj_after_close\": \"close\", \"vol\": \"volume\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "get_data_k('300076.SZ').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42566e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€šè¿‡AKshareè·å–Aè‚¡æ‰€æœ‰è‚¡ç¥¨ä»£ç \n",
    "stock_info_a_code_name_df = ak.stock_info_a_code_name()\n",
    "\n",
    "def AppendExchange(code):\n",
    "    if code[0] == '0':\n",
    "        return code+'.SZ'\n",
    "    elif code[0] == '3':\n",
    "        return code+'.SZ'\n",
    "    elif code[0] == '4':\n",
    "        return code+'.BJ'\n",
    "    elif code[0] == '5':\n",
    "        return code+'.SZ'\n",
    "    elif code[0] == '3':\n",
    "        return code+'.SZ'\n",
    "    elif code[0] == '6':\n",
    "        return code+'.SH'\n",
    "    elif code[0] == '8':\n",
    "        return code+'.BJ'\n",
    "    elif code[0] == '9':\n",
    "        return code+'.BJ'\n",
    "    else:\n",
    "        print(code)\n",
    "        return code\n",
    "\n",
    "stock_info_a_code_name_df['Code'] = stock_info_a_code_name_df['code'].apply(lambda x: AppendExchange(x))\n",
    "stock_info_a_code_name_df.to_csv('stock_list.csv', index=False,encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#æ²ªæ·±300æˆåˆ†è‚¡\n",
    "index_stock_cons_csindex_df = ak.index_stock_cons_csindex(symbol=\"000300\")\n",
    "#index_stock_cons_csindex_df.to_csv('Data/'+'stock_list_CSI300.csv', index=False,encoding='utf_8_sig')\n",
    "index_stock_cons_csindex_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e443d",
   "metadata": {},
   "source": [
    "# è·å–Aè‚¡Kçº¿æ•°æ®ï¼Œå¹¶å­˜æˆcsvæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.set_token('5d3c09f16bc3ad409898ff6cfc10aadeeae28ba23aa240c047dd125c')\n",
    "pro = ts.pro_api()\n",
    "\n",
    "# è·å– A è‚¡æ‰€æœ‰ä¸Šå¸‚å…¬å¸çš„ä»£ç å’Œåç§°\n",
    "stock_list = pd.read_csv('stock_list.csv', encoding='utf_8_sig')\n",
    "\n",
    "start_date = \"20050101\"\n",
    "end_date = \"20241231\"\n",
    "#tushare å­˜å‚¨è‚¡ç¥¨æ•°æ®è¿›å…¥CSV\n",
    "for index, row in stock_list.iterrows():\n",
    "    stock_code = row['Code']\n",
    "    stock_name = row['name']\n",
    "    # ç»„åˆæ–‡ä»¶åï¼Œä¾‹å¦‚ï¼šè´µå·èŒ…å° 600519.SH.csv\n",
    "    file_name = f\"{stock_name}_{stock_code}.csv\"\n",
    "    #f = open(\"Data/results.csv\",\"a\",encoding='utf_8_sig')\n",
    "\n",
    "    try:\n",
    "        # è·å–è‚¡ç¥¨æ—¥çº¿è¡Œæƒ…æ•°æ®ï¼Œå¯æ ¹æ®å®é™…éœ€æ±‚æ¢ç”¨å…¶ä»–åˆé€‚çš„æ•°æ®æ¥å£\n",
    "        stock_data = pro.daily(ts_code=stock_code, start_date=start_date, end_date=end_date)\n",
    "        stock_data = stock_data.iloc[::-1]\n",
    "        # å°†æ•°æ®ä¿å­˜ä¸º CSV æ–‡ä»¶\n",
    "        stock_data.to_csv('Data/'+file_name, index=False,encoding='utf_8_sig')\n",
    "        #print(f\"{index}-{stock_name}ï¼ˆ{stock_code}ï¼‰çš„æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° {file_name}\",file=f)\n",
    "        print(f\"{index}-{stock_name}ï¼ˆ{stock_code}ï¼‰çš„æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° {file_name}\")\n",
    "    except Exception as e:\n",
    "        #print(f\"è·å– {index}-{stock_name}ï¼ˆ{stock_code}ï¼‰çš„æ•°æ®æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}\",file=f)\n",
    "        print(f\"è·å– {index}-{stock_name}ï¼ˆ{stock_code}ï¼‰çš„æ•°æ®æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}\")\n",
    "\n",
    "    #f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1961175",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = pd.read_csv('stock_list.csv', encoding='utf_8_sig')\n",
    "stock_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ccc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '30076.sz'\n",
    "a[a.find('_')+1:a.find('.')]\n",
    "ak.stock_financial_abstract_ths(symbol='002141',indicator=\"æŒ‰æŠ¥å‘ŠæœŸ\")\n",
    "a = ['000506,']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e60c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = pd.read_csv('stock_11.csv', encoding='utf_8_sig')\n",
    "stock_list.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8dbcc",
   "metadata": {},
   "source": [
    "# è·å–Aè‚¡è´¢åŠ¡æ•°æ®ï¼Œå¹¶å­˜æˆcsvæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581515c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = pd.read_csv('stock_list.csv', encoding='utf_8_sig')\n",
    "\n",
    "for index, row in stock_list.iterrows():\n",
    "    stock_code = row['Code']\n",
    "    stock_name = row['name']\n",
    "    # ç»„åˆæ–‡ä»¶åï¼Œä¾‹å¦‚ï¼šè´µå·èŒ…å° 600519.SH.csv\n",
    "    file_name = f\"{stock_name}_{stock_code}.csv\"\n",
    "    f = open(\"results_financial_abstract.csv\",\"a\",encoding='utf_8_sig')\n",
    "\n",
    "    try:\n",
    "        # è·å–è´¢åŠ¡æ‘˜è¦æ•°æ®\n",
    "        stock_data = ak.stock_financial_abstract_ths(symbol=stock_code[:stock_code.find('.')],indicator=\"æŒ‰æŠ¥å‘ŠæœŸ\")\n",
    "        # å°†æ•°æ®ä¿å­˜ä¸º CSV æ–‡ä»¶\n",
    "        stock_data.to_csv('Data_financial_abstract/'+file_name, index=False,encoding='utf_8_sig')\n",
    "        print(f\"{index}-{stock_name}ï¼ˆ{stock_code}ï¼‰çš„æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° {file_name}\",file=f)\n",
    "        print(f\"{index}-{stock_name}ï¼ˆ{stock_code}ï¼‰çš„æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"è·å– {index}-{stock_name}ï¼ˆ{stock_code}ï¼‰çš„æ•°æ®æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}\",file=f)\n",
    "        print(f\"è·å– {index}-{stock_name}ï¼ˆ{stock_code}ï¼‰çš„æ•°æ®æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}\")\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830830fc",
   "metadata": {},
   "source": [
    "# tushareæ•°æ®æ¥å£å¹¶è½¬æ¢ä¸ºbacktraderèƒ½è¯†åˆ«çš„æ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tushare Proç‰ˆæœ¬\n",
    "ts.set_token('5d3c09f16bc3ad409898ff6cfc10aadeeae28ba23aa240c047dd125c')\n",
    "pro = ts.pro_api()\n",
    "\n",
    "start_date = '20170101'\n",
    "end_date = '20211201'\n",
    "code = '600519.SH'\n",
    "\n",
    "def get_data(code = code,start_date = start_date,end_date = end_date):\n",
    "    df = pro.daily(ts_code = code,start_date = start_date,end_date = end_date)\n",
    "    df = df.iloc[::-1]\n",
    "    df.index = pd.to_datetime(df.trade_date)\n",
    "    df['openinterest'] = 0\n",
    "    df = df[['open','high','low','close','vol','openinterest']]\n",
    "    df.rename(columns={'vol': 'volume'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "stock_df = get_data()\n",
    "data = bt.feeds.PandasData(\n",
    "    dataname=stock_df,\n",
    "    fromdate=pd.to_datetime(start_date),\n",
    "    todate=pd.to_datetime(end_date),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef609433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tushare è€ç‰ˆæœ¬çš„æ–¹å¼\n",
    "code = '600519'\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2018-05-01'\n",
    "\n",
    "def get_data(code = code,start_date = start_date,end_date = end_date):\n",
    "    df = ts.get_k_data(code,start = start_date,end = end_date)\n",
    "    df.index = pd.to_datetime(df.date)\n",
    "    df['openinterest'] = 0\n",
    "    # å¯¹dfçš„æ•°æ®åˆ—è¿›è¡Œä¸€ä¸ªæ•´åˆ\n",
    "    df = df[['open','high','low','close','volume','openinterest']]\n",
    "    print(df.head())\n",
    "    print(df.tail())\n",
    "    print(len(df))\n",
    "    return df\n",
    "\n",
    "stock_df = get_data()\n",
    "\n",
    "data = bt.feeds.PandasData(\n",
    "    dataname=stock_df,\n",
    "    fromdate=pd.to_datetime(start_date),\n",
    "    todate=pd.to_datetime(end_date)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = qs.utils.download_returns('TSLA')\n",
    "sp500 = qs.utils.download_returns('SPY')\n",
    "qs.reports.metrics(stock, benchmark=sp500)\n",
    "#qs.reports.basic(stock, benchmark=sp500)\n",
    "#qs.reports.full(stock, benchmark=sp500)\n",
    "#qs.plots.snapshot(stock,show=True)\n",
    "#qs.reports.html(stock, benchmark=sp500,output='report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c1c4c",
   "metadata": {},
   "source": [
    "# backtraderæ¥å£æ¨¡ç‰ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb38a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#åŸå§‹äº‹ä»¶ç­–ç•¥æ¨¡æ¿ï¼Œè¯·åŸºäºæ­¤æ”¹å†™\n",
    "class my_strategy_date(bt.Strategy):\n",
    "    #å…¨å±€è®¾å®šäº¤æ˜“ç­–ç•¥çš„å‚æ•°\n",
    "\n",
    "    def __init__(self):\n",
    "        # åˆå§‹åŒ–äº¤æ˜“æŒ‡ä»¤ã€ä¹°å–ä»·æ ¼å’Œæ‰‹ç»­è´¹\n",
    "        self.order = None\n",
    "\n",
    "    def next(self):\n",
    "        # æ£€æŸ¥æ˜¯å¦æŒä»“ \n",
    "        #print(str(self.datetime.date(0)))\n",
    "        if str(self.datetime.date(0)) in sell_date.keys(): \n",
    "            s_list=sell_date[str(self.datetime.date(0))]\n",
    "            for i in s_list:\n",
    "                self.order_target_percent(target=0,data=i)\n",
    "                \n",
    "        if str(self.datetime.date(0)) in buy_date.keys(): \n",
    "            s_list=buy_date[str(self.datetime.date(0))]\n",
    "            for i in s_list:\n",
    "                self.order_target_percent(target=0.9/len(s_list),data=i)\n",
    "                \n",
    "\n",
    "            \n",
    "    def log(self, txt, dt=None):\n",
    "        ''' è¾“å‡ºæ—¥å¿—'''\n",
    "        dt = dt or self.datas[0].datetime.date(0) # æ‹¿ç°åœ¨çš„æ—¥æœŸ\n",
    "        print('%s, %s' % (dt.isoformat(), txt))\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed, order.Canceled, order.Margin]:\n",
    "            if order.isbuy():\n",
    "                self.log(f\"\"\"ä¹°å…¥{order.data._name}, æˆäº¤é‡{order.executed.size}ï¼Œæˆäº¤ä»·{order.executed.price:.2f}\"\"\")\n",
    "            elif order.issell():\n",
    "                self.log(f\"\"\"å–å‡º{order.data._name}, æˆäº¤é‡{order.executed.size}ï¼Œæˆäº¤ä»·{order.executed.price:.2f}\"\"\")\n",
    "            self.bar_executed = len(self)\n",
    "\n",
    "        # Write down: no pending order\n",
    "        self.order = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee94606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "è‚¡ç¥¨æ•°æ®é‡‡é›†å™¨\n",
    "ä½¿ç”¨akshareè·å–è‚¡ç¥¨å†å²æ•°æ®çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "åŠŸèƒ½ç‰¹ç‚¹:\n",
    "1. å•ä¸ªè‚¡ç¥¨æ•°æ®è·å–\n",
    "2. æ‰¹é‡è‚¡ç¥¨æ•°æ®è·å–\n",
    "3. å¢é‡æ›´æ–°æ•°æ®ï¼ˆé¿å…é‡å¤ä¸‹è½½ï¼‰\n",
    "4. è‡ªåŠ¨åˆ›å»ºç›®å½•å’Œæ–‡ä»¶ç®¡ç†\n",
    "5. å¼‚å¸¸å¤„ç†å’Œè¿›åº¦æç¤º\n",
    "\n",
    "ä½œè€…: Bç«™æ·»çˆ¸å­¦python\n",
    "æ—¥æœŸ: 2025å¹´5æœˆ\n",
    "\"\"\"\n",
    "\n",
    "import akshare as ak\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "\n",
    "class StockDataCollector:\n",
    "    \"\"\"è‚¡ç¥¨æ•°æ®é‡‡é›†å™¨ç±»\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir=\"è‚¡ç¥¨æ•°æ®\"):\n",
    "        self.data_dir = data_dir\n",
    "        self._ensure_dir_exists()\n",
    "    \n",
    "    def _ensure_dir_exists(self):\n",
    "        \"\"\"ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨\"\"\"\n",
    "        if not os.path.exists(self.data_dir):\n",
    "            os.makedirs(self.data_dir)\n",
    "            print(f\"å·²åˆ›å»ºæ•°æ®ç›®å½•: {self.data_dir}\")\n",
    "    \n",
    "    def get_single_stock(self, stock_code, stock_name=None, \n",
    "                        start_date=\"20230101\", end_date=None):\n",
    "        \"\"\"\n",
    "        è·å–å•ä¸ªè‚¡ç¥¨æ•°æ®\n",
    "        \n",
    "        å‚æ•°:\n",
    "        stock_code: è‚¡ç¥¨ä»£ç  (å¦‚\"601318\")\n",
    "        stock_name: è‚¡ç¥¨åç§° (å¦‚\"ä¸­å›½å¹³å®‰\")ï¼Œå¯é€‰\n",
    "        start_date: å¼€å§‹æ—¥æœŸ (æ ¼å¼: \"20230101\")\n",
    "        end_date: ç»“æŸæ—¥æœŸ (æ ¼å¼: \"20231231\")ï¼Œé»˜è®¤ä¸ºä»Šå¤©\n",
    "        \n",
    "        è¿”å›:\n",
    "        DataFrame: è‚¡ç¥¨æ•°æ®\n",
    "        \"\"\"\n",
    "        if end_date is None:\n",
    "            end_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "        \n",
    "        if stock_name is None:\n",
    "            stock_name = f\"è‚¡ç¥¨_{stock_code}\"\n",
    "        \n",
    "        print(f\"æ­£åœ¨è·å– {stock_name}({stock_code}) æ•°æ®...\")\n",
    "        print(f\"æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}\")\n",
    "        \n",
    "        try:\n",
    "            # è·å–è‚¡ç¥¨å†å²æ—¥Kæ•°æ®\n",
    "            stock_data = ak.stock_zh_a_hist(\n",
    "                symbol=stock_code, \n",
    "                period=\"daily\", \n",
    "                start_date=start_date, \n",
    "                end_date=end_date,\n",
    "                adjust=\"\"  # ä¸å¤æƒ\n",
    "            )\n",
    "            \n",
    "            if stock_data.empty:\n",
    "                print(f\"è­¦å‘Š: {stock_name} æ²¡æœ‰è·å–åˆ°æ•°æ®\")\n",
    "                return stock_data\n",
    "            \n",
    "            # ä¿å­˜åˆ°Excelæ–‡ä»¶\n",
    "            file_name = f\"{self.data_dir}/{stock_name}_{stock_code}_æ—¥Kæ•°æ®.xlsx\"\n",
    "            stock_data.to_excel(file_name, index=False)\n",
    "            \n",
    "            print(f\"âœ“ æˆåŠŸä¿å­˜ {stock_name} æ•°æ®åˆ° {file_name}\")\n",
    "            print(f\"  æ•°æ®æ¡æ•°: {len(stock_data)}\")\n",
    "            print(f\"  æ—¥æœŸèŒƒå›´: {stock_data['æ—¥æœŸ'].min()} åˆ° {stock_data['æ—¥æœŸ'].max()}\")\n",
    "            \n",
    "            return stock_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— è·å– {stock_name} æ•°æ®å¤±è´¥: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def batch_get_stocks(self, stock_list, stock_names=None, \n",
    "                        start_date=\"20230101\", end_date=None):\n",
    "        \"\"\"\n",
    "        æ‰¹é‡è·å–å¤šä¸ªè‚¡ç¥¨æ•°æ®\n",
    "        \n",
    "        å‚æ•°:\n",
    "        stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ (å¦‚[\"600519\", \"601318\"])\n",
    "        stock_names: è‚¡ç¥¨åç§°åˆ—è¡¨ (å¦‚[\"è´µå·èŒ…å°\", \"ä¸­å›½å¹³å®‰\"])ï¼Œå¯é€‰\n",
    "        start_date: å¼€å§‹æ—¥æœŸ\n",
    "        end_date: ç»“æŸæ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©\n",
    "        \n",
    "        è¿”å›:\n",
    "        DataFrame: æ±‡æ€»çš„è‚¡ç¥¨æ•°æ®\n",
    "        \"\"\"\n",
    "        if end_date is None:\n",
    "            end_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "        \n",
    "        if stock_names is None:\n",
    "            stock_names = [f\"è‚¡ç¥¨_{code}\" for code in stock_list]\n",
    "        \n",
    "        if len(stock_list) != len(stock_names):\n",
    "            raise ValueError(\"è‚¡ç¥¨ä»£ç åˆ—è¡¨å’Œè‚¡ç¥¨åç§°åˆ—è¡¨é•¿åº¦ä¸åŒ¹é…\")\n",
    "        \n",
    "        print(f\"å¼€å§‹æ‰¹é‡è·å– {len(stock_list)} åªè‚¡ç¥¨æ•°æ®...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        all_data = pd.DataFrame()\n",
    "        success_count = 0\n",
    "        \n",
    "        for i, stock_code in enumerate(stock_list):\n",
    "            stock_name = stock_names[i]\n",
    "            print(f\"[{i+1}/{len(stock_list)}] å¤„ç† {stock_name}({stock_code})\")\n",
    "            \n",
    "            try:\n",
    "                # è·å–è‚¡ç¥¨å†å²æ•°æ®\n",
    "                stock_data = ak.stock_zh_a_hist(\n",
    "                    symbol=stock_code, \n",
    "                    period=\"daily\", \n",
    "                    start_date=start_date, \n",
    "                    end_date=end_date,\n",
    "                    adjust=\"\"\n",
    "                )\n",
    "                \n",
    "                if not stock_data.empty:\n",
    "                    # ä¿å­˜å•ä¸ªè‚¡ç¥¨æ–‡ä»¶\n",
    "                    file_name = f\"{self.data_dir}/{stock_name}_{stock_code}_æ—¥Kæ•°æ®.xlsx\"\n",
    "                    stock_data.to_excel(file_name, index=False)\n",
    "                    \n",
    "                    # æ·»åŠ è‚¡ç¥¨æ ‡è¯†ä¿¡æ¯\n",
    "                    stock_data[\"è‚¡ç¥¨ä»£ç \"] = stock_code\n",
    "                    stock_data[\"è‚¡ç¥¨åç§°\"] = stock_name\n",
    "                    all_data = pd.concat([all_data, stock_data], ignore_index=True)\n",
    "                    \n",
    "                    success_count += 1\n",
    "                    print(f\"  âœ“ æˆåŠŸè·å– {len(stock_data)} æ¡æ•°æ®\")\n",
    "                else:\n",
    "                    print(f\"  âš  æ²¡æœ‰è·å–åˆ°æ•°æ®\")\n",
    "                \n",
    "                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— è·å–å¤±è´¥: {e}\")\n",
    "        \n",
    "        # ä¿å­˜æ±‡æ€»æ•°æ®\n",
    "        if not all_data.empty:\n",
    "            summary_file = f\"{self.data_dir}/æ‰€æœ‰è‚¡ç¥¨æ—¥Kæ•°æ®æ±‡æ€».xlsx\"\n",
    "            all_data.to_excel(summary_file, index=False)\n",
    "            print(f\"\\nâœ“ å·²ä¿å­˜æ±‡æ€»æ•°æ®åˆ° {summary_file}\")\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(f\"æ‰¹é‡è·å–å®Œæˆ: æˆåŠŸ {success_count}/{len(stock_list)} åªè‚¡ç¥¨\")\n",
    "        \n",
    "        return all_data\n",
    "    \n",
    "    def update_stock_data(self, stock_list, stock_names=None):\n",
    "        \"\"\"\n",
    "        å¢é‡æ›´æ–°è‚¡ç¥¨æ•°æ®ï¼ˆåªè·å–æ–°å¢éƒ¨åˆ†ï¼‰\n",
    "        \n",
    "        å‚æ•°:\n",
    "        stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨\n",
    "        stock_names: è‚¡ç¥¨åç§°åˆ—è¡¨ï¼Œå¯é€‰\n",
    "        \n",
    "        è¿”å›:\n",
    "        DataFrame: æ–°å¢çš„æ•°æ®\n",
    "        \"\"\"\n",
    "        if stock_names is None:\n",
    "            stock_names = [f\"è‚¡ç¥¨_{code}\" for code in stock_list]\n",
    "        \n",
    "        if len(stock_list) != len(stock_names):\n",
    "            raise ValueError(\"è‚¡ç¥¨ä»£ç åˆ—è¡¨å’Œè‚¡ç¥¨åç§°åˆ—è¡¨é•¿åº¦ä¸åŒ¹é…\")\n",
    "        \n",
    "        today = datetime.now()\n",
    "        end_date = today.strftime(\"%Y%m%d\")\n",
    "        \n",
    "        print(f\"å¼€å§‹å¢é‡æ›´æ–° {len(stock_list)} åªè‚¡ç¥¨æ•°æ®...\")\n",
    "        print(f\"æ›´æ–°åˆ°æ—¥æœŸ: {end_date}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        all_updated_data = pd.DataFrame()\n",
    "        update_count = 0\n",
    "        \n",
    "        for i, stock_code in enumerate(stock_list):\n",
    "            stock_name = stock_names[i]\n",
    "            file_name = f\"{self.data_dir}/{stock_name}_{stock_code}_æ—¥Kæ•°æ®.xlsx\"\n",
    "            \n",
    "            print(f\"[{i+1}/{len(stock_list)}] æ£€æŸ¥ {stock_name}({stock_code})\")\n",
    "            \n",
    "            # ç¡®å®šå¼€å§‹æ—¥æœŸ\n",
    "            start_date = \"20200101\"  # é»˜è®¤èµ·å§‹æ—¥æœŸ\n",
    "            existing_data = pd.DataFrame()\n",
    "            \n",
    "            if os.path.exists(file_name):\n",
    "                try:\n",
    "                    existing_data = pd.read_excel(file_name)\n",
    "                    \n",
    "                    if not existing_data.empty:\n",
    "                        # è·å–æœ€æ–°æ—¥æœŸ\n",
    "                        latest_date = pd.to_datetime(existing_data[\"æ—¥æœŸ\"].max())\n",
    "                        \n",
    "                        # å¦‚æœæ•°æ®å·²ç»æ˜¯æœ€æ–°çš„ï¼Œè·³è¿‡\n",
    "                        if latest_date.date() >= today.date():\n",
    "                            print(f\"  âœ“ æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°\")\n",
    "                            continue\n",
    "                        \n",
    "                        # è®¾ç½®å¼€å§‹æ—¥æœŸä¸ºæœ€æ–°æ—¥æœŸçš„ä¸‹ä¸€å¤©\n",
    "                        start_date = (latest_date + timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "                        print(f\"  â†’ æœ€æ–°æ•°æ®æ—¥æœŸ: {latest_date.strftime('%Y-%m-%d')}\")\n",
    "                        print(f\"  â†’ æ›´æ–°æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}\")\n",
    "                    else:\n",
    "                        print(f\"  â†’ æ–‡ä»¶å­˜åœ¨ä½†ä¸ºç©ºï¼Œé‡æ–°è·å–æ•°æ®\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  âš  è¯»å–ç°æœ‰æ–‡ä»¶å¤±è´¥: {e}\")\n",
    "            else:\n",
    "                print(f\"  â†’ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé¦–æ¬¡è·å–æ•°æ®\")\n",
    "            \n",
    "            try:\n",
    "                # è·å–æ–°å¢æ•°æ®\n",
    "                new_data = ak.stock_zh_a_hist(\n",
    "                    symbol=stock_code, \n",
    "                    period=\"daily\", \n",
    "                    start_date=start_date, \n",
    "                    end_date=end_date,\n",
    "                    adjust=\"\"\n",
    "                )\n",
    "                \n",
    "                if not new_data.empty:\n",
    "                    if not existing_data.empty:\n",
    "                        # åˆå¹¶æ–°æ—§æ•°æ®\n",
    "                        combined_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "                        # å»é‡å¹¶æŒ‰æ—¥æœŸæ’åº\n",
    "                        combined_data = combined_data.drop_duplicates(subset=[\"æ—¥æœŸ\"]).sort_values(\"æ—¥æœŸ\")\n",
    "                        combined_data.to_excel(file_name, index=False)\n",
    "                        print(f\"  âœ“ å·²æ›´æ–°æ•°æ®ï¼Œæ–°å¢ {len(new_data)} æ¡è®°å½•\")\n",
    "                    else:\n",
    "                        # ç›´æ¥ä¿å­˜æ–°æ•°æ®\n",
    "                        new_data.to_excel(file_name, index=False)\n",
    "                        print(f\"  âœ“ å·²åˆ›å»ºæ–‡ä»¶ï¼ŒåŒ…å« {len(new_data)} æ¡è®°å½•\")\n",
    "                    \n",
    "                    # æ·»åŠ åˆ°æ±‡æ€»æ•°æ®\n",
    "                    new_data[\"è‚¡ç¥¨ä»£ç \"] = stock_code\n",
    "                    new_data[\"è‚¡ç¥¨åç§°\"] = stock_name\n",
    "                    all_updated_data = pd.concat([all_updated_data, new_data], ignore_index=True)\n",
    "                    \n",
    "                    update_count += 1\n",
    "                else:\n",
    "                    print(f\"  â—‹ æ²¡æœ‰æ–°æ•°æ®\")\n",
    "                \n",
    "                time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— æ›´æ–°å¤±è´¥: {e}\")\n",
    "        \n",
    "        # æ›´æ–°æ±‡æ€»æ–‡ä»¶\n",
    "        if not all_updated_data.empty:\n",
    "            summary_file = f\"{self.data_dir}/æ‰€æœ‰è‚¡ç¥¨æ—¥Kæ•°æ®æ±‡æ€».xlsx\"\n",
    "            \n",
    "            if os.path.exists(summary_file):\n",
    "                try:\n",
    "                    existing_summary = pd.read_excel(summary_file)\n",
    "                    combined_summary = pd.concat([existing_summary, all_updated_data], ignore_index=True)\n",
    "                    # å»é‡å¹¶æ’åº\n",
    "                    combined_summary = combined_summary.drop_duplicates(\n",
    "                        subset=[\"æ—¥æœŸ\", \"è‚¡ç¥¨ä»£ç \"]).sort_values([\"è‚¡ç¥¨ä»£ç \", \"æ—¥æœŸ\"])\n",
    "                    combined_summary.to_excel(summary_file, index=False)\n",
    "                    print(f\"\\nâœ“ å·²æ›´æ–°æ±‡æ€»æ•°æ®æ–‡ä»¶\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nâš  æ›´æ–°æ±‡æ€»æ–‡ä»¶å¤±è´¥: {e}\")\n",
    "            else:\n",
    "                all_updated_data.to_excel(summary_file, index=False)\n",
    "                print(f\"\\nâœ“ å·²åˆ›å»ºæ±‡æ€»æ•°æ®æ–‡ä»¶\")\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(f\"å¢é‡æ›´æ–°å®Œæˆ: æ›´æ–° {update_count}/{len(stock_list)} åªè‚¡ç¥¨\")\n",
    "        \n",
    "        return all_updated_data\n",
    "    \n",
    "    def get_stock_info(self, stock_code):\n",
    "        \"\"\"è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯\"\"\"\n",
    "        try:\n",
    "            # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯\n",
    "            info = ak.stock_individual_info_em(symbol=stock_code)\n",
    "            return info\n",
    "        except Exception as e:\n",
    "            print(f\"è·å–è‚¡ç¥¨ {stock_code} ä¿¡æ¯å¤±è´¥: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»ç¨‹åº - æ¼”ç¤ºå„ç§åŠŸèƒ½\"\"\"\n",
    "    print(\"ğŸ”¥ è‚¡ç¥¨æ•°æ®é‡‡é›†å™¨\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # åˆ›å»ºé‡‡é›†å™¨å®ä¾‹\n",
    "    collector = StockDataCollector()\n",
    "    \n",
    "    # é¢„å®šä¹‰çš„è‚¡ç¥¨åˆ—è¡¨\n",
    "    stock_codes = [\"600519\", \"601318\", \"000858\", \"600036\", \"000002\"]\n",
    "    stock_names = [\"è´µå·èŒ…å°\", \"ä¸­å›½å¹³å®‰\", \"äº”ç²®æ¶²\", \"æ‹›å•†é“¶è¡Œ\", \"ä¸‡ç§‘A\"]\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nè¯·é€‰æ‹©åŠŸèƒ½:\")\n",
    "        print(\"1. è·å–å•ä¸ªè‚¡ç¥¨æ•°æ®\")\n",
    "        print(\"2. æ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®\")\n",
    "        print(\"3. å¢é‡æ›´æ–°è‚¡ç¥¨æ•°æ®\")\n",
    "        print(\"4. æŸ¥çœ‹é¢„è®¾è‚¡ç¥¨åˆ—è¡¨\")\n",
    "        print(\"5. è‡ªå®šä¹‰è‚¡ç¥¨åˆ—è¡¨\")\n",
    "        print(\"0. é€€å‡ºç¨‹åº\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        choice = input(\"è¯·è¾“å…¥é€‰é¡¹ (0-5): \").strip()\n",
    "        \n",
    "        if choice == \"0\":\n",
    "            print(\"ğŸ‘‹ ç¨‹åºå·²é€€å‡º\")\n",
    "            break\n",
    "        \n",
    "        elif choice == \"1\":\n",
    "            print(\"\\nğŸ“ˆ å•ä¸ªè‚¡ç¥¨æ•°æ®è·å–\")\n",
    "            stock_code = input(\"è¯·è¾“å…¥è‚¡ç¥¨ä»£ç  (å¦‚601318): \").strip()\n",
    "            stock_name = input(\"è¯·è¾“å…¥è‚¡ç¥¨åç§° (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡): \").strip()\n",
    "            start_date = input(\"è¯·è¾“å…¥å¼€å§‹æ—¥æœŸ (å¦‚20230101ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): \").strip()\n",
    "            \n",
    "            if not stock_code:\n",
    "                print(\"è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º\")\n",
    "                continue\n",
    "            \n",
    "            if not stock_name:\n",
    "                stock_name = None\n",
    "            \n",
    "            if not start_date:\n",
    "                start_date = \"20230101\"\n",
    "            \n",
    "            collector.get_single_stock(stock_code, stock_name, start_date)\n",
    "        \n",
    "        elif choice == \"2\":\n",
    "            print(\"\\nğŸ“Š æ‰¹é‡è·å–è‚¡ç¥¨æ•°æ®\")\n",
    "            print(\"ä½¿ç”¨é¢„è®¾è‚¡ç¥¨åˆ—è¡¨:\")\n",
    "            for i, (code, name) in enumerate(zip(stock_codes, stock_names)):\n",
    "                print(f\"  {i+1}. {name}({code})\")\n",
    "            \n",
    "            start_date = input(\"è¯·è¾“å…¥å¼€å§‹æ—¥æœŸ (å¦‚20230101ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): \").strip()\n",
    "            if not start_date:\n",
    "                start_date = \"20230101\"\n",
    "            \n",
    "            collector.batch_get_stocks(stock_codes, stock_names, start_date)\n",
    "        \n",
    "        elif choice == \"3\":\n",
    "            print(\"\\nğŸ”„ å¢é‡æ›´æ–°è‚¡ç¥¨æ•°æ®\")\n",
    "            print(\"å°†æ›´æ–°é¢„è®¾è‚¡ç¥¨åˆ—è¡¨ä¸­çš„æ‰€æœ‰è‚¡ç¥¨...\")\n",
    "            \n",
    "            collector.update_stock_data(stock_codes, stock_names)\n",
    "        \n",
    "        elif choice == \"4\":\n",
    "            print(\"\\nğŸ“‹ å½“å‰é¢„è®¾è‚¡ç¥¨åˆ—è¡¨:\")\n",
    "            for i, (code, name) in enumerate(zip(stock_codes, stock_names)):\n",
    "                print(f\"  {i+1}. {name}({code})\")\n",
    "        \n",
    "        elif choice == \"5\":\n",
    "            print(\"\\nâœï¸ è‡ªå®šä¹‰è‚¡ç¥¨åˆ—è¡¨\")\n",
    "            print(\"è¯·è¾“å…¥è‚¡ç¥¨ä»£ç ï¼Œç”¨é€—å·åˆ†éš” (å¦‚: 600519,601318,000858)\")\n",
    "            codes_input = input(\"è‚¡ç¥¨ä»£ç : \").strip()\n",
    "            \n",
    "            if not codes_input:\n",
    "                print(\"è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º\")\n",
    "                continue\n",
    "            \n",
    "            custom_codes = [code.strip() for code in codes_input.split(\",\")]\n",
    "            \n",
    "            print(\"è¯·è¾“å…¥å¯¹åº”çš„è‚¡ç¥¨åç§°ï¼Œç”¨é€—å·åˆ†éš” (å¯é€‰)\")\n",
    "            names_input = input(\"è‚¡ç¥¨åç§°: \").strip()\n",
    "            \n",
    "            if names_input:\n",
    "                custom_names = [name.strip() for name in names_input.split(\",\")]\n",
    "                if len(custom_names) != len(custom_codes):\n",
    "                    print(\"è‚¡ç¥¨åç§°æ•°é‡ä¸ä»£ç æ•°é‡ä¸åŒ¹é…ï¼Œå°†ä½¿ç”¨é»˜è®¤åç§°\")\n",
    "                    custom_names = None\n",
    "            else:\n",
    "                custom_names = None\n",
    "            \n",
    "            action = input(\"é€‰æ‹©æ“ä½œ (1-æ‰¹é‡è·å–, 2-å¢é‡æ›´æ–°): \").strip()\n",
    "            \n",
    "            if action == \"1\":\n",
    "                start_date = input(\"è¯·è¾“å…¥å¼€å§‹æ—¥æœŸ (å¦‚20230101ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): \").strip()\n",
    "                if not start_date:\n",
    "                    start_date = \"20230101\"\n",
    "                collector.batch_get_stocks(custom_codes, custom_names, start_date)\n",
    "            elif action == \"2\":\n",
    "                collector.update_stock_data(custom_codes, custom_names)\n",
    "            else:\n",
    "                print(\"æ— æ•ˆé€‰é¡¹\")\n",
    "        \n",
    "        else:\n",
    "            print(\"æ— æ•ˆé€‰é¡¹ï¼Œè¯·é‡æ–°é€‰æ‹©\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
